@book{koza92,
		author    = "Koza, John R.",
		title     = "Genetic Programming: On the Programming of Computers by Means of Natural Selection",
		publisher = "MIT Press",
		year      = "1992"
}


@misc{ definicionIA,
       author = "Gobierno de España",
       title = "Definicion IA según la comisión europea",
       year = "2023",
       url = "https://planderecuperacion.gob.es/noticias/que-es-inteligencia-artificial-ia-prtr",
       note = "[Internet; recuperado el 7 de junio de 2025]"
}

@misc{ definicionTokens,
       author = "Microsoft",
       title = "Definicion Tokens según Microsoft",
       year = "2025",
       url = "https://learn.microsoft.com/es-es/dotnet/ai/conceptual/understanding-tokens",
       note = "[Internet; recuperado el 7 de junio de 2025]"
}

@misc{ DeepSeek-coder,
       author = "DeepSeek-coder",
       title = "DeepSeek-coder repositorio",
       year = "2025",
       url = "https://github.com/deepseek-ai/DeepSeek-Coder?tab=readme-ov-file",
       note = "[Internet; recuperado el 13 de junio de 2025]"
}

@misc{ RAG-Amazon,
       author = "Amazon",
       title = "¿Qué es la RAG (generación aumentada por recuperación)?",
       year = "2025",
       url = "https://aws.amazon.com/what-is/retrieval-augmented-generation/#:~:text=Retrieval,effective",
       note = "[Internet; recuperado el 21 de junio de 2025]"
}

@misc{ HuggingFace-LoRA,
       author = "Younes B Tim Dettmers Artidoro Pagnoni Sylvain Gugger Sourab Mangrulkar",
       title = "Making LLMs even more accessible with bitsandbytes, 4-bit quantization and QLoRA",
       year = "2025",
       url = "https://huggingface.co/blog/4bit-transformers-bitsandbytes#:~:text=QLoRA%20tuning%20is%20shown%20to,the%20power%20of%20QLoRA%20tuning",
       note = "[Internet; recuperado el 21 de junio de 2025]"
}

@misc{ CloudFlare-LoRA,
       author = "CloudFlare",
       title = "¿Qué es la adaptación de bajo rango (LoRA)?",
       year = "2025",
       url = "https://www.cloudflare.com/es-es/learning/ai/what-is-lora/",
       note = "[Internet; recuperado el 21 de junio de 2025]"
}

@misc{ Gpu-Finetuning,
       author = "Sebastian Buzdugan",
       title = "What’s the Best GPU for Fine-Tuning LLMs? A No-Nonsense Guide",
       year = "2025",
       url = "https://medium.com/@sebuzdugan/whats-the-best-gpu-for-fine-tuning-llms-a-no-nonsense-guide-239fefc5cd38",
       note = "[Internet; recuperado el 21 de junio de 2025]"
}

@misc{ Ollama,
       author = "Ollama",
       title = "Ollama",
       year = "2025",
       url = "https://ollama.com/",
       note = "[Internet; recuperado el 5 de julio de 2025]"
}

@misc{ InformacionOllama,
       author = "Diego B",
       title = "¿Qué es Ollama? Principales características y modelos",
       year = "2025",
       url = "https://www.hostinger.com/es/tutoriales/que-es-ollama#Ventajas_de_utilizar_Ollama",
       note = "[Internet; recuperado el 5 de julio de 2025]"
}

@misc{ GithubOllama,
       author = "Ollama",
       title = "Ollama",
       year = "2025",
       url = "https://github.com/ollama/ollama",
       note = "[Internet; recuperado el 5 de julio de 2025]"
}

@misc{ Unsloth,
       author = "Unsloth",
       title = "Unsloth",
       year = "2025",
       url = "https://unsloth.ai/",
       note = "[Internet; recuperado el 25 de septiembre de 2025]"
}

@misc{historiaCascada,
author = {{Martín Alaimo}},
title  = {{Modelo de cascada: Ventajas y desventajas}},
howpublished = {\url{https://medium.com/@kleer.la/waterfall-la-historia-detr%C3%A1s-del-error-39f589a12115}},
note = {Último acceso: Octubre 2025}
}

@misc{cascada,
author = {{Lucidchart}},
title  = {{Waterfall. La historia detrás del error}},
howpublished = {\url{https://www.lucidchart.com/blog/es/pros-y-contras-de-la-metodologia-de-cascada}},
note = {Último acceso: Octubre 2025}
}
@misc{formatoLlama2,
author = {{Meta}},
title  = {{formatoLlama2}},
howpublished = {\url{https://www.llama.com/docs/model-cards-and-prompt-formats/meta-llama-2/}},
note = {Último acceso: Diciembre 2025}
}

@misc{pytorch,
author = {{pytorch}},
title  = {{pytorch}},
howpublished = {\url{https://pytorch.org/
}},
note = {Último acceso: Diciembre 2025}
}

@misc{transformers,
author = {{huggingFace}},
title  = {{transformers}},
howpublished = {\url{https://huggingface.co/docs/transformers/index}},
note = {Último acceso: Diciembre 2025}
}

@misc{datasets,
author = {{huggingFace}},
title  = {{datasets}},
howpublished = {\url{https://huggingface.co/docs/datasets/index}},
note = {Último acceso: Diciembre 2025}
}


@misc{openwebui,
author = {{openwebui}},
title  = {{openwebui}},
howpublished = {\url{https://docs.openwebui.com/}},
note = {Último acceso: Diciembre 2025}
}

@misc{ganttProyect,
author = {{ganttProyect}},
title  = {{ganttProyect}},
howpublished = {\url{https://www.ganttproject.biz/}},
note = {Último acceso: Diciembre 2025}
}