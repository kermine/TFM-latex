\capitulo{3}{Conceptos teóricos}
En este capítulo nos centraremos especialmente en la terminología y conceptos teóricos necesarios para el entendimiento del proyecto, todos los conceptos explicados a continuación han tenido que ser investigados, estudiados y comprendidos por el alumno, de tal manera de poder llegar así a la solución planteada.
\section{Terminología empleada}
\begin{itemize}
      \item Inteligencia Artificial (IA): Según la comisión europea son sistemas de software (y posiblemente también de hardware) diseñados por humanos que, ante un objetivo complejo, actúan en la dimensión física o digital percibiendo su entorno, a través de la adquisición e interpretación de datos estructurados o no estructurados y razonando sobre el conocimiento, procesando la información derivada de estos datos y decidiendo las mejores acciones para lograr el objetivo dado. \cite{definicionIA}
      \item Modelo extenso de lenguaje (LLM): se trata de modelos que son entrenados con grandes cantidades de texto proveniente de artículos, dentro de estos podemos diferenciar entre los LLM tradicionales, aquellos que han sido entrenados unicamente con texto como por ejemplo GPT-3, LLaMA y los LLM Multimodales que han sido entrenados con otras fuentes de información que no es solo texto, como imágenes, video y audio.
    \item Parámetros del modelo: matrices numéricas que ajustan cómo el modelo  transforma los datos de entrada en salida, a mayor numero de parámetros mayor capacidad de aprendizaje y compresión de patrones, pero también supone un mayor consumo de memoria y coste computacional
    \item Tokens: Los tokens son palabras, juegos de caracteres o combinaciones de palabras y puntuación que generan los modelos de lenguaje grandes (LLM) cuando descomponen el texto. La tokenización es el primer paso del entrenamiento.
    \item Dataset de entrenamiento: conjunto de datos con cierta estructura que es capaz de entender el modelo con el fin de reentrenarlo para la tarea especifica de los datos.
.
\end{itemize}
